{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAA9JJREFUeJzt3dFN40AARVGyolZTk6en1OQtYLVRiMkY+57zDbKBXM0PT3Pbtu0D6Plz9AsAxxA/RIkfosQPUeKHKPFDlPghSvwQJX6I+pz5sDHG9H8nXJZl9iM/xhjTn3k267oe/QqXdb/fb898nZMfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BB1m3xphxtCLqQyXT7b/NikF3hI/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfoi6/6tuzPDvikk8eqywJ91iWxaoP+D/xQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9ETZ30jjFc1Pkm5sfvc7YZsUkv8JD4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EfR79As/4+vo6+hW+ZV3X6c90ISnf5eSHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0RNnfSebZr7qj0/5xFzYJqc/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUae4qHOPykrOZZvvs+d3u+cC1Xdz8kOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfoqZOeivz2rN59WJRf89zc/JDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0Rd/qLOszniwk3rvCYnP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghyqT3DY6Y5fI7vfpZGGP88Jv8y8kPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BBl1feAdR5X5uSHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0RdftJrlssZzfjcOvkhSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6Iuv+qDMxpjvPy9zy4CnfwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1Hih6hTTHpdtkmNizqBtxE/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oeo27ZtM5839WFwVjsv6rw983VOfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFD1OxJL/BLOPkhSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHqL/f0Vwd+iCClAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "imageSet=[]\n",
    "controllerSet=[]\n",
    "cwd = Path().resolve()\n",
    "def showImage(imageData):\n",
    "\t%matplotlib inline\n",
    "\tfig = plt.figure()\n",
    "\tplotwindow = fig.add_subplot(111)\n",
    "\tplt.axis('off')\n",
    "\tplt.imshow(imageData, interpolation='nearest',cmap='gray')\n",
    "\tplt.show()\n",
    "def ParseFullData():  #tradition way\n",
    "\tglobal imageSet,controllerSet\n",
    "\tmodule_path = cwd \n",
    "\tdataFileName = str(module_path) + \"/testOct1611.txt\"\n",
    "\twith open(dataFileName, \"r\") as f:\n",
    "\t\tx=0\n",
    "\t\tfor line in f.readlines():\n",
    "\t\t\tline=line.strip()\n",
    "\t\t\tif x%2==0:\n",
    "\t\t\t\timageSet.append(list(map(int,line.split(\" \"))))\n",
    "\t\t\telse:\n",
    "\t\t\t\tcontrollerSet.append(list(map(int,line.split(\" \"))))\n",
    "\t\t\tx+=1\n",
    "\timageSet = np.array(imageSet)\n",
    "\timageSet = imageSet.reshape(len(imageSet),15,15)\n",
    "\tshowImage(imageSet[60])\n",
    "\tprint(controllerSet[60])\n",
    "ParseFullData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 84,806\n",
      "Trainable params: 84,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "IMAGE_DIMS=[15,15,1]\n",
    "class SmallerVGGNet:\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth):\n",
    "\t\t# initialize the model along with the input shape to be\n",
    "\t\t# \"channels last\" and the channels dimension itself\n",
    "\t\tmodel = models.Sequential()\n",
    "\t\t# CONV => RELU => POOL\n",
    "\t\tmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(height, width, depth)))\n",
    "\t\tmodel.add(layers.MaxPooling2D((2, 2)))\n",
    "\t\tmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\t\t# model.summary()\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(layers.Flatten())\n",
    "\t\tmodel.add(layers.Dense(64, activation='relu'))\n",
    "\t\tmodel.add(layers.Dense(6, activation='softmax'))\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model\n",
    "model = SmallerVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],depth=IMAGE_DIMS[2])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(367, 15, 15)      (367,)\n",
      "367 [1 0 0 0 0 0]\n",
      "293 74 293 74\n",
      "(293, 15, 15, 1)\n",
      "Epoch 1/5\n",
      "293/293 [==============================] - 7s 24ms/step - loss: 1.5082 - acc: 0.4164\n",
      "Epoch 2/5\n",
      "293/293 [==============================] - 0s 491us/step - loss: 1.3979 - acc: 0.5085\n",
      "Epoch 3/5\n",
      "293/293 [==============================] - 0s 386us/step - loss: 1.3270 - acc: 0.5392\n",
      "Epoch 4/5\n",
      "293/293 [==============================] - 0s 413us/step - loss: 1.3168 - acc: 0.5461\n",
      "Epoch 5/5\n",
      "293/293 [==============================] - 0s 427us/step - loss: 1.2414 - acc: 0.5495\n",
      "74/74 [==============================] - 0s 2ms/step\n",
      "0.5270270302488997\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "imageSet=[]\n",
    "controllerSet=[]\n",
    "cwd = Path().resolve()\n",
    "def KerasPreprocessing():\n",
    "\tdata = np.array(imageSet, dtype=\"float\") / 255.0\n",
    "\tdata = data.reshape(len(data), 15, 15)\n",
    "\t# print(len(controllerSet))\n",
    "\t# print(len(imageSet))\n",
    "\tlabels = classifyController()\n",
    "\tlabels = np.array(labels)\n",
    "\t# print(labels[10:20])\n",
    "\t# print(len(data),len(labels))\n",
    "\tprint(data.shape, \"    \",labels.shape )\n",
    "\tlb = LabelBinarizer()\n",
    "\tlabels = lb.fit_transform(labels)\n",
    "\tprint(len(labels),labels[0])\n",
    "\t(train_images, test_images, train_labels, test_labels) = train_test_split(data,labels, test_size=0.2, random_state=42)\n",
    "\tprint(len(train_images),len(test_images),len(train_labels),len(test_labels))\n",
    "\ttrain_images = np.expand_dims(train_images, axis=3)\n",
    "\tprint(train_images.shape)\n",
    "\ttest_images = np.expand_dims(test_images, axis=3)\n",
    "\t# print(train_images[0]) #image \n",
    "\t# print(test_images[0]) #lable\n",
    "\tmodel = models.Sequential()\n",
    "\t# CONV => RELU => POOL\n",
    "\tmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(15, 15, 1)))\n",
    "\tmodel.add(layers.MaxPooling2D((2, 2)))\n",
    "\tmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\t# model.summary()\n",
    "\t# softmax classifier\n",
    "\tmodel.add(layers.Flatten())\n",
    "\tmodel.add(layers.Dense(64, activation='relu'))\n",
    "\tmodel.add(layers.Dense(6, activation='softmax'))\n",
    "\tmodel.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\tmodel.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "\ttest_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\tprint(test_acc)\n",
    "def classifyController():\n",
    "\tlabels=[]\n",
    "\tfor controller in controllerSet:\n",
    "\t\tif controller[1]==1:\n",
    "\t\t\tif controller[6]==1:\n",
    "\t\t\t\tlabels.append(\"LB\")\n",
    "\t\t\telif controller[7]==1:\n",
    "\t\t\t\tlabels.append(\"RB\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tlabels.append(\"B\")\n",
    "\t\telif controller[6]==1:\n",
    "\t\t\tlabels.append(\"L\")\n",
    "\t\telif controller[7]==1:\n",
    "\t\t\tlabels.append(\"R\")\n",
    "\t\telse:\n",
    "\t\t\tlabels.append(\"\")\n",
    "\treturn labels\n",
    "def ParseFullData(FileName):  #tradition way\n",
    "\tglobal imageSet,controllerSet\n",
    "\tmodule_path = cwd \n",
    "\tdataFileName = str(module_path) + FileName \n",
    "\twith open(dataFileName, \"r\") as f:\n",
    "\t\tx=0\n",
    "\t\tfor line in f.readlines():\n",
    "\t\t\tline=line.strip()\n",
    "\t\t\tif x%2==0:\n",
    "\t\t\t\timageSet.append(list(map(int,line.split(\" \"))))\n",
    "\t\t\telse:\n",
    "\t\t\t\tcontrollerSet.append(list(map(int,line.split(\" \"))))\n",
    "\t\t\tx+=1\n",
    "\tclassifyController()\n",
    "\tKerasPreprocessing()\n",
    "ParseFullData(\"/testOct1611.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1002, 15, 15)      (1002,)\n",
      "1002 [1 0 0 0 0 0]\n",
      "801 201 801 201\n",
      "(801, 15, 15, 1)\n",
      "Epoch 1/5\n",
      "801/801 [==============================] - 1s 1ms/step - loss: 1.5513 - acc: 0.4357\n",
      "Epoch 2/5\n",
      "801/801 [==============================] - 0s 373us/step - loss: 1.4608 - acc: 0.4707\n",
      "Epoch 3/5\n",
      "801/801 [==============================] - 0s 356us/step - loss: 1.4083 - acc: 0.4744\n",
      "Epoch 4/5\n",
      "801/801 [==============================] - 0s 353us/step - loss: 1.3712 - acc: 0.4844\n",
      "Epoch 5/5\n",
      "801/801 [==============================] - 0s 357us/step - loss: 1.3223 - acc: 0.4919\n",
      "201/201 [==============================] - 0s 866us/step\n",
      "0.5174129357681939\n"
     ]
    }
   ],
   "source": [
    "imageSet=[]\n",
    "controllerSet=[]\n",
    "def ParseFullData(FileName):  #tradition way\n",
    "\tglobal imageSet,controllerSet\n",
    "\tmodule_path = cwd \n",
    "\tdataFileName = str(module_path) + FileName\n",
    "\twith open(dataFileName, \"r\") as f:\n",
    "\t\tx=0\n",
    "\t\tfor line in f.readlines():\n",
    "\t\t\tline=line.strip()\n",
    "\t\t\tif x%2==0:\n",
    "\t\t\t\timageSet.append(list(map(int,line.split(\" \"))))\n",
    "\t\t\telse:\n",
    "\t\t\t\tcontrollerSet.append(list(map(int,line.split(\" \"))))\n",
    "\t\t\tx+=1\n",
    "\tclassifyController()\n",
    "\tKerasPreprocessing()\n",
    "ParseFullData(\"/testOct2510.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1369, 15, 15)      (1369,)\n",
      "1369 [1 0 0 0 0 0]\n",
      "1095 274 1095 274\n",
      "(1095, 15, 15, 1)\n",
      "Epoch 1/5\n",
      "1095/1095 [==============================] - 1s 989us/step - loss: 1.4786 - acc: 0.4740\n",
      "Epoch 2/5\n",
      "1095/1095 [==============================] - 0s 421us/step - loss: 1.3951 - acc: 0.5032\n",
      "Epoch 3/5\n",
      "1095/1095 [==============================] - 1s 459us/step - loss: 1.3303 - acc: 0.5041\n",
      "Epoch 4/5\n",
      "1095/1095 [==============================] - 0s 436us/step - loss: 1.2947 - acc: 0.5041\n",
      "Epoch 5/5\n",
      "1095/1095 [==============================] - 0s 375us/step - loss: 1.2482 - acc: 0.5370\n",
      "274/274 [==============================] - 0s 704us/step\n",
      "0.5000000013052112\n"
     ]
    }
   ],
   "source": [
    "imageSet=[]\n",
    "controllerSet=[]\n",
    "def ParseFullData(FileName):  #tradition way\n",
    "\tglobal imageSet,controllerSet\n",
    "\tmodule_path = cwd \n",
    "\tdataFileName = str(module_path) + FileName\n",
    "\twith open(dataFileName, \"r\") as f:\n",
    "\t\tx=0\n",
    "\t\tfor line in f.readlines():\n",
    "\t\t\tline=line.strip()\n",
    "\t\t\tif x%2==0:\n",
    "\t\t\t\timageSet.append(list(map(int,line.split(\" \"))))\n",
    "\t\t\telse:\n",
    "\t\t\t\tcontrollerSet.append(list(map(int,line.split(\" \"))))\n",
    "\t\t\tx+=1\n",
    "\tKerasPreprocessing()\n",
    "ParseFullData(\"/FullData.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noneActionSet 0\n",
      "leftSet 125\n",
      "leftBoostSet 180\n",
      "rightSet 78\n",
      "rightBoostSet 209\n",
      "boostSet 658\n",
      "(1250, 15, 15)      (1250,)\n",
      "1250 [0 0 1 0 0]\n",
      "1000 250 1000 250\n",
      "(1000, 15, 15, 1)\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 947us/step - loss: 1.3064 - acc: 0.5000\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 463us/step - loss: 1.1956 - acc: 0.5410\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 381us/step - loss: 1.1326 - acc: 0.5470\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 381us/step - loss: 1.0619 - acc: 0.5660\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 487us/step - loss: 1.0458 - acc: 0.5760 0s - loss: 1.1120 - acc: \n",
      "250/250 [==============================] - 0s 828us/step\n",
      "0.5800000023841858\n"
     ]
    }
   ],
   "source": [
    "imageSet=[]\n",
    "controllerSet=[]\n",
    "leftSet=[]\n",
    "rightSet=[]\n",
    "leftBoostSet=[]\n",
    "rightBoostSet=[]\n",
    "boostSet=[]\n",
    "noneActionSet=[]\n",
    "cwd = Path().resolve()\n",
    "def KerasPreprocessingNew():\n",
    "\tdata = np.array(imageSet, dtype=\"float\") / 255.0\n",
    "\tdata = data.reshape(len(data), 15, 15)\n",
    "\t# print(len(controllerSet))\n",
    "\t# print(len(imageSet))\n",
    "\tlabels = classifyController()\n",
    "\tlabels = np.array(labels)\n",
    "\t# print(labels[10:20])\n",
    "\t# print(len(data),len(labels))\n",
    "\tprint(data.shape, \"    \",labels.shape )\n",
    "\tlb = LabelBinarizer()\n",
    "\tlabels = lb.fit_transform(labels)\n",
    "\tprint(len(labels),labels[0])\n",
    "\t(train_images, test_images, train_labels, test_labels) = train_test_split(data,labels, test_size=0.2, random_state=42)\n",
    "\tprint(len(train_images),len(test_images),len(train_labels),len(test_labels))\n",
    "\ttrain_images = np.expand_dims(train_images, axis=3)\n",
    "\tprint(train_images.shape)\n",
    "\ttest_images = np.expand_dims(test_images, axis=3)\n",
    "\t# print(train_images[0]) #image \n",
    "\t# print(test_images[0]) #lable\n",
    "\tmodel = models.Sequential()\n",
    "\t# CONV => RELU => POOL\n",
    "\tmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(15, 15, 1)))\n",
    "\tmodel.add(layers.MaxPooling2D((2, 2)))\n",
    "\tmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\t# model.summary()\n",
    "\t# softmax classifier\n",
    "\tmodel.add(layers.Flatten())\n",
    "\tmodel.add(layers.Dense(64, activation='relu'))\n",
    "\tmodel.add(layers.Dense(5, activation='softmax'))\n",
    "\tmodel.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\tmodel.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "\ttest_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\tprint(test_acc)\n",
    "    \n",
    "def isNullAction(list):\n",
    "\tfor i in list:\n",
    "\t\tif i != 0:\n",
    "\t\t\treturn False\n",
    "\treturn True\n",
    "\n",
    "def classify(image,controller):  # Deprecated only for validate Data\n",
    "\tglobal leftSet,rightSet,leftBoostSet,rightBoostSet,boostSet\n",
    "\tif controller[1]==1:        #boost\n",
    "\t\tif controller[6]==1:\n",
    "\t\t\tleftBoostSet.append(image)\n",
    "\t\telif controller[7]==1:\n",
    "\t\t\trightBoostSet.append(image)\n",
    "\t\telse:\n",
    "\t\t\tboostSet.append(image)\n",
    "\telif controller[6]==1:\n",
    "\t\tleftSet.append(image)\n",
    "\telif controller[7]==1:\n",
    "\t\trightSet.append(image)\n",
    "\telse:\n",
    "\t\tnoneActionSet.append(image)\n",
    "\n",
    "def optimiseData():\n",
    "\tglobal imageSet,controllerSet\n",
    "\tfast = 0\n",
    "\tslow = 0\n",
    "\tfor fast in range(len(imageSet)):\n",
    "\t\tif(not isNullAction(controllerSet[fast])):\n",
    "\t\t\timageSet[slow] = imageSet[fast]\n",
    "\t\t\tcontrollerSet[slow] = controllerSet[fast]\n",
    "\t\t\tslow+=1;\n",
    "\t\t\tfast+=1;\n",
    "\t\telse:\n",
    "\t\t\tfast+=1;\n",
    "\timageSet = imageSet[0 : slow]\n",
    "\tcontrollerSet = controllerSet[0 : slow]\n",
    "\tfor (x,y) in zip(imageSet,controllerSet):\n",
    "\t\tclassify(x,y)\n",
    "\t# print(optimisedLabel)\n",
    "\tprint(\"noneActionSet\",len(noneActionSet))\n",
    "\tprint(\"leftSet\",len(leftSet))\n",
    "\tprint(\"leftBoostSet\",len(leftBoostSet))\n",
    "\tprint(\"rightSet\",len(rightSet))\n",
    "\tprint(\"rightBoostSet\",len(rightBoostSet))\n",
    "\tprint(\"boostSet\",len(boostSet))\n",
    "\n",
    "def ParseFullData(FileName):  #tradition way\n",
    "\tglobal imageSet,controllerSet\n",
    "\tmodule_path = cwd \n",
    "\tdataFileName = str(module_path) + FileName\n",
    "\twith open(dataFileName, \"r\") as f:\n",
    "\t\tx=0\n",
    "\t\tfor line in f.readlines():\n",
    "\t\t\tline=line.strip()\n",
    "\t\t\tif x%2==0:\n",
    "\t\t\t\timageSet.append(list(map(int,line.split(\" \"))))\n",
    "\t\t\telse:\n",
    "\t\t\t\tcontrollerSet.append(list(map(int,line.split(\" \"))))\n",
    "\t\t\tx+=1\n",
    "\t# for i in range(len(imageSet)):     \t# find the Wrong Data\n",
    "\t# \tif len(imageSet[i]) != 225:\n",
    "\t# \t\tprint(i,\"   \",len(imageSet[i]))\n",
    "\t# print(len(imageSet))\n",
    "\toptimiseData()\n",
    "\tKerasPreprocessingNew()\n",
    "\n",
    "ParseFullData(\"/FullData.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
